# üìù Publications

A full publication list is available on my [Google Scholar](https://scholar.google.com/citations?user=pg7iOtcAAAAJ) page.

{% include paper-box.html
   venue="BMVC 2025"
   image="images/paper_teasers/climb3d.png"
   title="CLIMB-3D: Continual Learning for Imbalanced 3D Instance Segmentation"
   link="https://arxiv.org/abs/2502.17429"
   authors="<strong>Vishal Thengane</strong>, Jean Lahoud, Hisham Cholakkal, Rao Muhammad Anwer, Lu Yin, Xiatian Zhu, Salman Khan"
   arxiv="https://arxiv.org/abs/2502.17429"
   github="https://github.com/vgthengane/CLIMB3D"
   project="https://github.com/vgthengane/CLIMB3D"
   description="
We introduce class-incremental learning for point cloud instance segmentation and curate benchmarks from the long-tail ScanNet200 dataset. To address class imbalance, we propose a novel module that ensures more uniform performance across frequent and rare classes.
"
%}

{% include paper-box.html
   venue="CVPR 2023"
   image="images/paper_teasers/continual_clip.png"
   title="CLIP Model is an Efficient Continual Learner"
   link="https://sites.google.com/view/clvision2023/call-for-papers/accepted-papers"
   authors="<strong>Vishal Thengane</strong>, Salman Khan, Munawar Hayat, Fahad Khan"
   arxiv="https://arxiv.org/abs/2210.03114"
   github="https://github.com/vgthengane/Continual-CLIP"
   project="https://github.com/vgthengane/Continual-CLIP"
   description="This work demonstrates that a frozen CLIP model, evaluated in zero-shot mode, achieves SOTA performance across multiple continual learning settings without any fine-tuning. Tested on five benchmarks, CLIP surpasses existing methods while avoiding re-training, memory replay, or architectural tweaks, making it a strong and surprisingly simple baseline for future CL research."
%}

{% include paper-box.html
   venue="ECCV 2022"
   image="/images/paper_teasers/fm3d_survey.png"
   title="Strong Gravitational Lensing Parameter Estimation with Vision Transformer"
   link="https://link.springer.com/chapter/10.1007/978-3-031-25056-9_10"
   authors="Kuan-Wei Huang, Geoff Chih-Fan Chen, Po-Wen Chang, Sheng-Chieh Lin, Chia-Jung Hsu, <strong>Vishal Thengane</strong>, Joshua Yao-Yu Lin"
   arxiv="https://arxiv.org/abs/2210.04143"
   github="https://github.com/kuanweih/strong_lensing_vit_resnet"
   description="We explore Vision Transformers (ViTs) for estimating parameters in simulated lensed quasar systems‚Äîoffering a fast, competitive alternative to MCMC and CNNs. ViTs perform well on mass-related lensing parameters, showing promise for future lensing analyses."
%}

## Pre-prints

{% include paper-box.html
   venue="Arxiv 2025"
   image="/images/paper_teasers/fm3d_survey.png"
   title="Foundational Models for 3D Point Clouds: A Survey and Outlook"
   link="https://arxiv.org/abs/2501.18594"
   authors="<strong>Vishal Thengane</strong>, Xiatian Zhu, Salim Bouzerdoum, Son Lam Phung, Yunpeng Li"
   arxiv="https://arxiv.org/abs/2501.18594"
   github="https://github.com/vgthengane/Awesome-FMs-in-3D"
   description="This paper surveys recent advances in foundation models for 3D point cloud understanding, focusing on how 2D and language-based pretrained models help overcome challenges like limited labelled data and high computational costs. It reviews strategies for building 3D FMs, their application across core 3D tasks, and highlights future research directions."
%}

{% include paper-box.html
   venue="Arxiv 2024"
   image="/images/paper_teasers/gcsl.png"
   title="Gradient Correlation Subspace Learning against Catastrophic Forgetting"
   link="https://arxiv.org/abs/2403.02334"
   authors="<strong>Vishal Thengane</strong>, Tammuz Dubnov"
   arxiv="https://arxiv.org/abs/2403.02334"
   github="https://github.com/vgthengane/GCSL"
   description="This paper proposes Gradient Correlation Subspace Learning (GCSL) to address catastrophic forgetting in incremental class learning. GCSL identifies and preserves weight subspaces least affected by prior tasks, projecting new task updates into them, and can be flexibly applied across network layers and tasks."
%}